{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b97d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import dspy\n",
    "\n",
    "\n",
    "with open(\"xai_key.txt\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=api_key)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "HW3_ROOT = os.getcwd()   \n",
    "PRAG_DATA_DIR = os.path.join(HW3_ROOT, \"PragmatiCQA\", \"data\")\n",
    "SOURCES_DIR   = os.path.join(HW3_ROOT, \"PragmatiCQA-sources\")\n",
    "\n",
    "VAL_JSONL   = os.path.join(PRAG_DATA_DIR, \"val.jsonl\")\n",
    "TRAIN_JSONL = os.path.join(PRAG_DATA_DIR, \"train.jsonl\")\n",
    "TEST_JSONL  = os.path.join(PRAG_DATA_DIR, \"test.jsonl\")\n",
    "\n",
    "\n",
    "\n",
    "TOP_K_RETRIEVE = 5 \n",
    "SEED = 42\n",
    "\n",
    "@dataclass\n",
    "class FirstTurnExample:\n",
    "    topic: str\n",
    "    question: str\n",
    "    gold_answer: str                  \n",
    "    literal_spans: List[str]           \n",
    "    pragmatic_spans: List[str]        \n",
    "    conversation_id: str               \n",
    "\n",
    "def read_jsonl(path: str) -> List[Dict]:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbb6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 179 first-question examples from val.jsonl\n",
      "Sample:\n",
      "topic: A Nightmare on Elm Street (2010 film)\n",
      "question: who is freddy krueger? ...\n",
      "gold_answer: Freddy Kruger is the nightmare in nighmare on Elm street. Please note, and to be very clear, the system that loads up wi ...\n",
      "#literal_spans: 1 | #pragmatic_spans: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "def _extract_span_texts(objs: Optional[List[Dict[str, Any]]]) -> List[str]:\n",
    "    \"\"\"Safely extract the 'text' field from a_meta.literal_obj / pragmatic_obj entries.\"\"\"\n",
    "    if not objs:\n",
    "        return []\n",
    "    out = []\n",
    "    for obj in objs:\n",
    "        txt = obj.get(\"text\")\n",
    "        if isinstance(txt, str) and txt.strip():\n",
    "            out.append(txt.strip())\n",
    "    return out\n",
    "\n",
    "def load_first_questions(val_jsonl_path: str) -> List[FirstTurnExample]:\n",
    "    rows = read_jsonl(val_jsonl_path)\n",
    "    examples: List[FirstTurnExample] = []\n",
    "\n",
    "    for i, conv in enumerate(rows):\n",
    "        topic = conv.get(\"topic\", \"\").strip()\n",
    "        qas = conv.get(\"qas\") or []\n",
    "        if not qas:\n",
    "            continue  \n",
    "\n",
    "        first = qas[0]\n",
    "        question = (first.get(\"q\") or \"\").strip()\n",
    "        gold_answer = (first.get(\"a\") or \"\").strip()\n",
    "\n",
    "        a_meta = first.get(\"a_meta\") or {}\n",
    "        literal_objs = a_meta.get(\"literal_obj\") or []\n",
    "        pragmatic_objs = a_meta.get(\"pragmatic_obj\") or []\n",
    "\n",
    "        literal_spans = _extract_span_texts(literal_objs)\n",
    "        pragmatic_spans = _extract_span_texts(pragmatic_objs)\n",
    "\n",
    "        ex = FirstTurnExample(\n",
    "            topic=topic or f\"[UNKNOWN_TOPIC_{i}]\",\n",
    "            question=question,\n",
    "            gold_answer=gold_answer,\n",
    "            literal_spans=literal_spans,\n",
    "            pragmatic_spans=pragmatic_spans,\n",
    "            conversation_id=str(i),\n",
    "        )\n",
    "        examples.append(ex)\n",
    "\n",
    "    return examples\n",
    "\n",
    "val_first_q_examples = load_first_questions(VAL_JSONL)\n",
    "print(f\"[INFO] Loaded {len(val_first_q_examples)} first-question examples from val.jsonl\")\n",
    "if val_first_q_examples:\n",
    "    e0 = val_first_q_examples[0]\n",
    "    print(\"Sample:\")\n",
    "    print(\"topic:\", e0.topic)\n",
    "    print(\"question:\", e0.question[:120], \"...\")\n",
    "    print(\"gold_answer:\", e0.gold_answer[:120], \"...\")\n",
    "    print(\"#literal_spans:\", len(e0.literal_spans), \"| #pragmatic_spans:\", len(e0.pragmatic_spans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07150a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: A Nightmare on Elm Street (2010 film)\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Built FAISS index | topic='A Nightmare on Elm Street (2010 film)' | dir='A Nightmare on Elm Street' | #chunks=33827\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3 (Unified): Topic resolver + FAISS retriever ===\n",
    "from typing import List, Tuple, Optional\n",
    "import os, re, glob, difflib\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ----------------------------------------------------\n",
    "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(EMB_MODEL_NAME)\n",
    "\n",
    "_topic_to_index: dict[str, faiss.Index] = {}\n",
    "_topic_to_chunks: dict[str, List[str]] = {}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "def normalize_topic_to_dirname(topic: str) -> str:\n",
    "    t = topic.strip()\n",
    "    t = re.sub(r\"\\s*\\([^)]*\\)\", \"\", t)          \n",
    "    t = re.sub(r\"[^0-9A-Za-z _-]+\", \" \", t)    \n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = t.replace(\" \", \"_\")\n",
    "    return t\n",
    "\n",
    "def list_available_topics_dirs() -> list:\n",
    "    if not os.path.isdir(SOURCES_DIR):\n",
    "        print(f\"[ERROR] Sources dir missing: {SOURCES_DIR}\")\n",
    "        return []\n",
    "    return [d for d in os.listdir(SOURCES_DIR) if os.path.isdir(os.path.join(SOURCES_DIR, d))]\n",
    "\n",
    "def resolve_topic_dir(topic: str) -> Optional[str]:\n",
    "    candidates = list_available_topics_dirs()\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    norm = normalize_topic_to_dirname(topic)\n",
    "    direct = os.path.join(SOURCES_DIR, norm)\n",
    "    if os.path.isdir(direct):\n",
    "        return direct\n",
    "\n",
    "    match = difflib.get_close_matches(norm, candidates, n=1, cutoff=0.6)\n",
    "    if match:\n",
    "        print(f\"[INFO] Fuzzy-resolved topic '{topic}' -> '{match[0]}'\")\n",
    "        return os.path.join(SOURCES_DIR, match[0])\n",
    "\n",
    "    raw = topic.replace(\" \", \"_\")\n",
    "    raw_match = difflib.get_close_matches(raw, candidates, n=1, cutoff=0.6)\n",
    "    if raw_match:\n",
    "        print(f\"[INFO] Fuzzy-resolved (raw) '{topic}' -> '{raw_match[0]}'\")\n",
    "        return os.path.join(SOURCES_DIR, raw_match[0])\n",
    "\n",
    "    print(f\"[WARN] Could not resolve topic folder for: {topic} (norm='{norm}')\")\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------------------\n",
    "def build_faiss_index_for_topic(topic: str) -> None:\n",
    "    topic_dir = resolve_topic_dir(topic)\n",
    "    if not topic_dir:\n",
    "        print(f\"[WARN] Topic dir not found for topic: {topic}\")\n",
    "        return\n",
    "\n",
    "    html_files = glob.glob(os.path.join(topic_dir, \"*.html\"))\n",
    "    chunks: List[str] = []\n",
    "    for f in html_files:\n",
    "        with open(f, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "            text = fh.read()\n",
    "        for para in text.split(\"\\n\"):\n",
    "            para = para.strip()\n",
    "            if len(para) > 30:\n",
    "                chunks.append(para)\n",
    "\n",
    "    if not chunks:\n",
    "        print(f\"[WARN] No chunks for topic '{topic}' (dir='{topic_dir}')\")\n",
    "        return\n",
    "\n",
    "    X = embedder.encode(chunks, convert_to_numpy=True, show_progress_bar=False)\n",
    "    faiss.normalize_L2(X)\n",
    "    index = faiss.IndexFlatIP(X.shape[1]) \n",
    "    index.add(X)\n",
    "\n",
    "    _topic_to_index[topic] = index\n",
    "    _topic_to_chunks[topic] = chunks\n",
    "    print(f\"[INFO] Built FAISS index | topic='{topic}' | dir='{os.path.basename(topic_dir)}' | #chunks={len(chunks)}\")\n",
    "\n",
    "def retrieve_context(topic: str, question: str, top_k: int = TOP_K_RETRIEVE) -> List[str]:\n",
    "    resolved_dir = resolve_topic_dir(topic)\n",
    "    if not resolved_dir:\n",
    "        print(f\"[WARN] Could not resolve dir for topic: {topic}\")\n",
    "\n",
    "    if topic not in _topic_to_index:\n",
    "        build_faiss_index_for_topic(topic)\n",
    "    if topic not in _topic_to_index:\n",
    "        return []\n",
    "\n",
    "    index = _topic_to_index[topic]\n",
    "    chunks = _topic_to_chunks[topic]\n",
    "\n",
    "    q_emb = embedder.encode([question], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "\n",
    "    return [chunks[i] for i in I[0] if 0 <= i < len(chunks)]\n",
    "\n",
    "sample_ex = val_first_q_examples[0]\n",
    "print(\"Topic:\", sample_ex.topic)\n",
    "ctx = retrieve_context(sample_ex.topic, sample_ex.question, top_k=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef5da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "Coop Query: Detailed biography of Freddy Krueger: origins in A Nightmare on Elm Street, creator, characteristics, and cultural significance.\n",
      "Answer (preview): Freddy Krueger, whose full name is Frederick Charles \"Freddy\" Krueger, is a fictional character from the \"A Nightmare on Elm Street\" horror film franchise. He is often referred to as Fred Krueger and is portrayed as a vengeful dream-haunting antagonist with a burned appearance and a signature clawed ...\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from typing import List, Tuple, Optional\n",
    "class SummarizeGoal(dspy.Signature):\n",
    "    \"\"\"Summarize the student's long-term goal or interests from prior Q/A history.\"\"\"\n",
    "    history = dspy.InputField(desc=\"List of prior (question, answer) pairs, oldest→newest.\")\n",
    "    summary = dspy.OutputField(desc=\"2-4 concise sentences summarizing goals/interests.\")\n",
    "\n",
    "class InferPragmaticNeed(dspy.Signature):\n",
    "    \"\"\"Infer the current pragmatic need behind the student's question.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    history_summary = dspy.InputField()\n",
    "    retrieved_glimpse = dspy.InputField(desc=\"Short excerpt(s) of the retrieved context.\")\n",
    "    need = dspy.OutputField(desc=\"Crisp statement of what extra info would be most helpful now.\")\n",
    "\n",
    "class GenerateCoopQuery(dspy.Signature):\n",
    "    \"\"\"Generate a cooperative follow-up retrieval query to fetch complementary context.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    pragmatic_need = dspy.InputField()\n",
    "    coop_query = dspy.OutputField(desc=\"A single focused query for the retriever (<= 160 chars).\")\n",
    "\n",
    "class ReasonCoT(dspy.Signature):\n",
    "    \"\"\"Deliberate on how to craft a cooperative answer grounded in the retrieved evidence.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    history_summary = dspy.InputField()\n",
    "    all_context = dspy.InputField(desc=\"Concise merged evidence snippets to ground the answer.\")\n",
    "    pragmatic_need = dspy.InputField()\n",
    "    reasoning = dspy.OutputField(desc=\"Step-by-step plan: literal facts to include + helpful extras.\")\n",
    "\n",
    "class CooperativeAnswer(dspy.Signature):\n",
    "    \"\"\"Produce a cooperative answer grounded in retrieved evidence.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    history_summary = dspy.InputField()\n",
    "    all_context = dspy.InputField()\n",
    "    reasoning = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Final cooperative answer. Cite evidence implicitly; avoid hallucinations; be concise and helpful.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "def _format_history(history: Optional[List[Tuple[str, str]]]) -> str:\n",
    "    if not history:\n",
    "        return \"(no prior turns)\"\n",
    "    lines = []\n",
    "    for i, (q, a) in enumerate(history, 1):\n",
    "        lines.append(f\"Turn {i} - Q: {q}\\nTurn {i} - A: {a}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _shorten_chunks(chunks: List[str], max_chars: int = 1000) -> str:\n",
    "    \"\"\"Concatenate chunks with a soft character budget (for prompting).\"\"\"\n",
    "    out, used = [], 0\n",
    "    for c in chunks:\n",
    "        c = c.strip()\n",
    "        if not c:\n",
    "            continue\n",
    "        if used + len(c) + 2 > max_chars:\n",
    "            break\n",
    "        out.append(c)\n",
    "        used += len(c) + 2\n",
    "    return \"\\n---\\n\".join(out)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "class MultiStepCoopQAModule(dspy.Module):\n",
    "    def __init__(self, retriever_fn, top_k: int = 5, second_hop: bool = True):\n",
    "        \"\"\"\n",
    "        retriever_fn: callable(topic: str, question: str, top_k: int) -> List[str]\n",
    "        top_k: כמה קטעים לשלוף בכל שאילתה.\n",
    "        second_hop: האם לבצע שליפה שניה עם ה-coop query.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.retriever_fn = retriever_fn\n",
    "        self.top_k = top_k\n",
    "        self.second_hop = second_hop\n",
    "\n",
    "        self.summarize = dspy.Predict(SummarizeGoal)\n",
    "        self.infer_need = dspy.Predict(InferPragmaticNeed)\n",
    "        self.gen_query = dspy.Predict(GenerateCoopQuery)\n",
    "        self.reason = dspy.Predict(ReasonCoT)\n",
    "        self.answer = dspy.Predict(CooperativeAnswer)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        *,\n",
    "        topic: str,\n",
    "        question: str,\n",
    "        history: Optional[List[Tuple[str, str]]] = None,\n",
    "        initial_context: Optional[List[str]] = None,\n",
    "        top_k: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        API ראשי:\n",
    "          - topic: שם הטופיק (לשליפה מתוך ה-HTMLים שלו)\n",
    "          - question: השאלה הנוכחית\n",
    "          - history: [(q,a), ...] (ב-4.4.1 לרוב None)\n",
    "          - initial_context: אם כבר שלפת קטעים מראש (אפשר להשאיר None)\n",
    "          - top_k: גובר על self.top_k אם סופק\n",
    "        מחזיר: dict עם שלבי ביניים + answer סופי.\n",
    "        \"\"\"\n",
    "        k = top_k or self.top_k\n",
    "\n",
    "        ctx1 = initial_context\n",
    "        if ctx1 is None:\n",
    "            ctx1 = self.retriever_fn(topic, question, top_k=k)\n",
    "        ctx1_short = _shorten_chunks(ctx1, max_chars=800) if ctx1 else \"(no context retrieved)\"\n",
    "\n",
    "        history_txt = _format_history(history)\n",
    "\n",
    "        summary = self.summarize(history=history_txt).summary\n",
    "        need = self.infer_need(\n",
    "            question=question,\n",
    "            history_summary=summary,\n",
    "            retrieved_glimpse=ctx1_short\n",
    "        ).need\n",
    "\n",
    "        coop_q = self.gen_query(\n",
    "            question=question,\n",
    "            pragmatic_need=need\n",
    "        ).coop_query\n",
    "\n",
    "        ctx_all = list(ctx1) if ctx1 else []\n",
    "        if self.second_hop and coop_q and isinstance(coop_q, str) and len(coop_q.strip()) > 0:\n",
    "            ctx2 = self.retriever_fn(topic, coop_q.strip(), top_k=max(2, k // 2))\n",
    "            if ctx2:\n",
    "                ctx_all.extend(ctx2)\n",
    "\n",
    "        ctx_all_short = _shorten_chunks(ctx_all, max_chars=1600) if ctx_all else ctx1_short\n",
    "        plan = self.reason(\n",
    "            question=question,\n",
    "            history_summary=summary,\n",
    "            all_context=ctx_all_short,\n",
    "            pragmatic_need=need\n",
    "        ).reasoning\n",
    "\n",
    "        final = self.answer(\n",
    "            question=question,\n",
    "            history_summary=summary,\n",
    "            all_context=ctx_all_short,\n",
    "            reasoning=plan\n",
    "        ).answer\n",
    "\n",
    "        return {\n",
    "            \"history_summary\": summary,\n",
    "            \"pragmatic_need\": need,\n",
    "            \"coop_query\": coop_q,\n",
    "            \"context_1\": ctx1[:k] if ctx1 else [],\n",
    "            \"context_all\": ctx_all[: (k + max(2, k // 2)) ],\n",
    "            \"reasoning\": plan,\n",
    "            \"answer\": final,\n",
    "        }\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "multi_step = MultiStepCoopQAModule(retriever_fn=retrieve_context, top_k=TOP_K_RETRIEVE, second_hop=True)\n",
    "\n",
    "probe = multi_step(\n",
    "    topic=val_first_q_examples[0].topic,\n",
    "    question=val_first_q_examples[0].question,\n",
    "    history=None,               \n",
    "    initial_context=None,       \n",
    "    top_k=3\n",
    ")\n",
    "print(\"Coop Query:\", probe[\"coop_query\"])\n",
    "print(\"Answer (preview):\", (probe[\"answer\"] or \"\")[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc512989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   0%|          | 0/179 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   1%|          | 1/179 [00:26<1:19:09, 26.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   1%|          | 2/179 [00:49<1:12:44, 24.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   2%|▏         | 3/179 [01:16<1:14:41, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n",
      "[INFO] Fuzzy-resolved topic 'A Nightmare on Elm Street (2010 film)' -> 'A Nightmare on Elm Street'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\A Nightmare on Elm Street\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   2%|▏         | 4/179 [01:55<1:29:32, 30.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Built FAISS index | topic='Batman' | dir='Batman' | #chunks=122677\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   3%|▎         | 5/179 [33:20<33:48:19, 699.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   3%|▎         | 6/179 [33:48<22:38:25, 471.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   4%|▍         | 7/179 [34:11<15:31:09, 324.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   4%|▍         | 8/179 [34:35<10:52:10, 228.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   5%|▌         | 9/179 [35:03<7:51:05, 166.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   6%|▌         | 10/179 [35:31<5:47:54, 123.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   6%|▌         | 11/179 [35:57<4:22:30, 93.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   7%|▋         | 12/179 [36:24<3:23:48, 73.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   7%|▋         | 13/179 [36:59<2:50:50, 61.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   8%|▊         | 14/179 [37:23<2:18:29, 50.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:   9%|▉         | 17/179 [37:52<1:03:54, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  10%|█         | 18/179 [38:17<1:04:08, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  11%|█         | 19/179 [38:43<1:05:25, 24.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  11%|█         | 20/179 [39:06<1:03:31, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  12%|█▏        | 21/179 [39:37<1:08:29, 26.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  12%|█▏        | 22/179 [40:03<1:08:00, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  13%|█▎        | 23/179 [40:31<1:09:18, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  13%|█▎        | 24/179 [41:01<1:11:24, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  14%|█▍        | 25/179 [41:34<1:14:35, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  15%|█▍        | 26/179 [42:11<1:19:56, 31.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  15%|█▌        | 27/179 [42:42<1:19:19, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  16%|█▌        | 28/179 [43:11<1:16:58, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  16%|█▌        | 29/179 [43:38<1:13:46, 29.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  17%|█▋        | 30/179 [44:05<1:11:39, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  17%|█▋        | 31/179 [44:33<1:10:21, 28.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  18%|█▊        | 32/179 [44:59<1:08:12, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  18%|█▊        | 33/179 [45:33<1:12:21, 29.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  19%|█▉        | 34/179 [45:58<1:08:16, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  20%|█▉        | 35/179 [46:20<1:03:16, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  20%|██        | 36/179 [46:45<1:01:43, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  21%|██        | 37/179 [47:23<1:10:21, 29.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  21%|██        | 38/179 [47:50<1:08:01, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  22%|██▏       | 39/179 [48:17<1:06:02, 28.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  22%|██▏       | 40/179 [48:44<1:04:49, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  23%|██▎       | 41/179 [49:09<1:02:20, 27.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Batman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  23%|██▎       | 42/179 [49:40<1:04:22, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Built FAISS index | topic='Supernanny' | dir='Supernanny' | #chunks=4463\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  24%|██▍       | 43/179 [50:54<1:34:48, 41.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  25%|██▍       | 44/179 [51:21<1:23:52, 37.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  25%|██▌       | 45/179 [51:50<1:18:03, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  26%|██▌       | 46/179 [52:17<1:12:17, 32.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  26%|██▋       | 47/179 [52:44<1:07:41, 30.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  27%|██▋       | 48/179 [53:09<1:03:46, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  27%|██▋       | 49/179 [53:41<1:05:12, 30.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  28%|██▊       | 50/179 [54:10<1:03:42, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  28%|██▊       | 51/179 [54:37<1:01:41, 28.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  29%|██▉       | 52/179 [55:02<58:22, 27.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  30%|██▉       | 53/179 [55:24<54:54, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  30%|███       | 54/179 [55:54<56:44, 27.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  31%|███       | 55/179 [56:20<55:31, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  31%|███▏      | 56/179 [56:43<52:35, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  32%|███▏      | 57/179 [57:08<51:33, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  32%|███▏      | 58/179 [57:52<1:02:17, 30.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  33%|███▎      | 59/179 [58:34<1:08:47, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  34%|███▎      | 60/179 [59:02<1:04:35, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  34%|███▍      | 61/179 [59:27<59:26, 30.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  35%|███▍      | 62/179 [59:56<58:18, 29.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  35%|███▌      | 63/179 [1:00:28<58:37, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  36%|███▌      | 64/179 [1:00:53<55:03, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  36%|███▋      | 65/179 [1:01:22<55:07, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  37%|███▋      | 66/179 [1:01:44<50:28, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Supernanny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  37%|███▋      | 67/179 [1:02:12<50:58, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  38%|███▊      | 68/179 [1:02:34<47:34, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  39%|███▊      | 69/179 [1:02:59<46:36, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  39%|███▉      | 70/179 [1:03:23<45:19, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  40%|███▉      | 71/179 [1:03:47<44:16, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  40%|████      | 72/179 [1:04:13<44:48, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  41%|████      | 73/179 [1:04:36<43:13, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  41%|████▏     | 74/179 [1:05:12<48:51, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  42%|████▏     | 76/179 [1:05:41<37:12, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  43%|████▎     | 77/179 [1:06:05<37:52, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  44%|████▍     | 79/179 [1:06:29<30:01, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  45%|████▍     | 80/179 [1:06:54<32:25, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  45%|████▌     | 81/179 [1:07:18<33:45, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  46%|████▋     | 83/179 [1:07:42<27:27, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Could not resolve dir for topic: Alexander Hamilton\n",
      "[WARN] Could not resolve topic folder for: Alexander Hamilton (norm='Alexander_Hamilton')\n",
      "[WARN] Topic dir not found for topic: Alexander Hamilton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  47%|████▋     | 84/179 [1:08:10<31:00, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  47%|████▋     | 85/179 [1:08:40<34:34, 22.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  48%|████▊     | 86/179 [1:09:05<35:40, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Could not resolve dir for topic: The Wonderful Wizard of Oz (book)\n",
      "[WARN] Could not resolve topic folder for: The Wonderful Wizard of Oz (book) (norm='The_Wonderful_Wizard_of_Oz')\n",
      "[WARN] Topic dir not found for topic: The Wonderful Wizard of Oz (book)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  49%|████▊     | 87/179 [1:09:31<36:11, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Built FAISS index | topic='Jujutsu Kaisen' | dir='Jujutsu Kaisen' | #chunks=87181\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  49%|████▉     | 88/179 [1:33:51<10:43:22, 424.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  50%|████▉     | 89/179 [1:34:22<7:48:11, 312.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  50%|█████     | 90/179 [1:34:48<5:40:13, 229.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  51%|█████     | 91/179 [1:35:11<4:07:46, 168.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  51%|█████▏    | 92/179 [1:35:37<3:03:54, 126.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  52%|█████▏    | 93/179 [1:36:07<2:20:43, 98.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n",
      "[INFO] Fuzzy-resolved topic 'Jujutsu Kaisen' -> 'Jujutsu Kaisen'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Jujutsu Kaisen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  53%|█████▎    | 94/179 [1:36:37<1:50:20, 77.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Enter the Gungeon' -> 'Enter the Gungeon'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Enter the Gungeon\n",
      "[INFO] Fuzzy-resolved topic 'Enter the Gungeon' -> 'Enter the Gungeon'\n",
      "[INFO] Built FAISS index | topic='Enter the Gungeon' | dir='Enter the Gungeon' | #chunks=38013\n",
      "[INFO] Fuzzy-resolved topic 'Enter the Gungeon' -> 'Enter the Gungeon'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Enter the Gungeon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  53%|█████▎    | 95/179 [1:46:23<5:21:03, 229.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Built FAISS index | topic='Dinosaur' | dir='Dinosaur' | #chunks=91220\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  54%|█████▎    | 96/179 [2:12:57<14:41:24, 637.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  54%|█████▍    | 97/179 [2:13:29<10:23:26, 456.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  55%|█████▍    | 98/179 [2:13:53<7:20:52, 326.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  55%|█████▌    | 99/179 [2:14:22<5:16:42, 237.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  56%|█████▌    | 100/179 [2:14:46<3:48:26, 173.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  56%|█████▋    | 101/179 [2:15:11<2:47:41, 128.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  57%|█████▋    | 102/179 [2:15:40<2:07:18, 99.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  58%|█████▊    | 103/179 [2:16:05<1:37:25, 76.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  58%|█████▊    | 104/179 [2:16:29<1:16:06, 60.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  59%|█████▊    | 105/179 [2:16:56<1:02:43, 50.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  59%|█████▉    | 106/179 [2:17:19<51:47, 42.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  60%|█████▉    | 107/179 [2:17:43<44:08, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  60%|██████    | 108/179 [2:18:05<38:27, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  61%|██████    | 109/179 [2:18:30<35:16, 30.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  61%|██████▏   | 110/179 [2:18:58<34:04, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  62%|██████▏   | 111/179 [2:19:25<32:23, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  63%|██████▎   | 112/179 [2:19:48<30:17, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  63%|██████▎   | 113/179 [2:20:12<28:40, 26.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  64%|██████▎   | 114/179 [2:20:37<27:57, 25.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  64%|██████▍   | 115/179 [2:21:01<27:01, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  65%|██████▍   | 116/179 [2:21:32<28:15, 26.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  65%|██████▌   | 117/179 [2:21:58<27:30, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  66%|██████▌   | 118/179 [2:22:33<29:38, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  66%|██████▋   | 119/179 [2:23:09<31:14, 31.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  67%|██████▋   | 120/179 [2:23:31<27:52, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  68%|██████▊   | 121/179 [2:24:02<28:21, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  68%|██████▊   | 122/179 [2:24:33<28:16, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  69%|██████▊   | 123/179 [2:24:57<26:09, 28.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Dinosaur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  69%|██████▉   | 124/179 [2:25:25<25:35, 27.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'The Karate Kid' -> 'The Karate Kid'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\The Karate Kid\n",
      "[INFO] Fuzzy-resolved topic 'The Karate Kid' -> 'The Karate Kid'\n",
      "[INFO] Built FAISS index | topic='The Karate Kid' | dir='The Karate Kid' | #chunks=41163\n",
      "[INFO] Fuzzy-resolved topic 'The Karate Kid' -> 'The Karate Kid'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\The Karate Kid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  70%|██████▉   | 125/179 [2:35:34<3:02:12, 202.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'The Karate Kid' -> 'The Karate Kid'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\The Karate Kid\n",
      "[INFO] Fuzzy-resolved topic 'The Karate Kid' -> 'The Karate Kid'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\The Karate Kid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  70%|███████   | 126/179 [2:36:05<2:13:15, 150.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  71%|███████   | 127/179 [2:36:33<1:38:44, 113.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  72%|███████▏  | 128/179 [2:36:53<1:12:53, 85.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  72%|███████▏  | 129/179 [2:37:20<56:57, 68.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  73%|███████▎  | 130/179 [2:37:58<48:10, 58.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  73%|███████▎  | 131/179 [2:38:25<39:34, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  74%|███████▎  | 132/179 [2:38:48<32:32, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  74%|███████▍  | 133/179 [2:39:18<29:16, 38.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  75%|███████▍  | 134/179 [2:39:39<24:49, 33.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  75%|███████▌  | 135/179 [2:39:58<21:02, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  76%|███████▌  | 136/179 [2:40:19<19:01, 26.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  77%|███████▋  | 138/179 [2:40:56<15:27, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  78%|███████▊  | 139/179 [2:41:19<15:12, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  78%|███████▊  | 140/179 [2:41:54<16:55, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  79%|███████▉  | 141/179 [2:42:19<16:13, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  79%|███████▉  | 142/179 [2:42:46<16:03, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  80%|███████▉  | 143/179 [2:43:06<14:36, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  80%|████████  | 144/179 [2:43:36<15:11, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  81%|████████  | 145/179 [2:43:58<14:03, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Could not resolve dir for topic: Popeye\n",
      "[WARN] Could not resolve topic folder for: Popeye (norm='Popeye')\n",
      "[WARN] Topic dir not found for topic: Popeye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  82%|████████▏ | 146/179 [2:44:22<13:33, 24.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Built FAISS index | topic='Game of Thrones' | dir='Game of Thrones' | #chunks=238161\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  82%|████████▏ | 147/179 [3:32:15<7:43:26, 868.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  83%|████████▎ | 148/179 [3:32:43<5:19:39, 618.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  83%|████████▎ | 149/179 [3:33:08<3:40:52, 441.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  84%|████████▍ | 150/179 [3:33:33<2:33:16, 317.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  84%|████████▍ | 151/179 [3:33:58<1:47:13, 229.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  85%|████████▌ | 153/179 [3:34:23<51:10, 118.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  86%|████████▌ | 154/179 [3:34:54<38:14, 91.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  87%|████████▋ | 155/179 [3:35:23<29:16, 73.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  87%|████████▋ | 156/179 [3:35:55<23:13, 60.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  88%|████████▊ | 157/179 [3:36:22<18:34, 50.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  88%|████████▊ | 158/179 [3:36:50<15:18, 43.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  89%|████████▉ | 160/179 [3:37:15<08:30, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  90%|████████▉ | 161/179 [3:37:40<07:52, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  91%|█████████ | 162/179 [3:38:12<07:53, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  91%|█████████ | 163/179 [3:38:41<07:30, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  92%|█████████▏| 164/179 [3:39:07<06:54, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  92%|█████████▏| 165/179 [3:39:35<06:26, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  93%|█████████▎| 166/179 [3:40:10<06:28, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  93%|█████████▎| 167/179 [3:40:34<05:36, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  94%|█████████▍| 168/179 [3:41:05<05:19, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  94%|█████████▍| 169/179 [3:41:27<04:28, 26.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  95%|█████████▍| 170/179 [3:41:52<03:57, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  96%|█████████▌| 171/179 [3:42:14<03:20, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  96%|█████████▌| 172/179 [3:42:45<03:07, 26.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  97%|█████████▋| 173/179 [3:43:13<02:44, 27.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  97%|█████████▋| 174/179 [3:43:42<02:18, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  98%|█████████▊| 175/179 [3:44:08<01:49, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  98%|█████████▊| 176/179 [3:44:37<01:23, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  99%|█████████▉| 177/179 [3:45:06<00:55, 27.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions:  99%|█████████▉| 178/179 [3:45:37<00:28, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n",
      "[INFO] Fuzzy-resolved topic 'Game of Thrones' -> 'Game of Thrones'\n",
      "[INFO] Using topic dir: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\PragmatiCQA-sources\\Game of Thrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultiStep on first questions: 100%|██████████| 179/179 [3:46:02<00:00, 75.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Done 179 examples in 13562.5s (75.77s/ex)\n",
      "[INFO] Saved to: c:\\Users\\gilic\\hw3\\nlp-with-llms-2025-hw3\\outputs\\val_firstq_multistep_predictions.jsonl\n",
      "Total predictions: 179\n",
      "--------------------------------------------------------------------------------\n",
      "Q: who is freddy krueger?\n",
      "Pred: Freddy Krueger, whose full name is Frederick Charles \"Freddy\" Krueger, is the central antagonist in the \"A Nightmare on Elm Street\" film series. He was a notorious child murderer with pre-death victims, who was killed by vigilante parents and later returned as a supernatural entity that haunts and k ...\n",
      "Gold: Freddy Kruger is the nightmare in nighmare on Elm street. Please note, and to be very clear, the system that loads up wiki is not allowing access to Adam Prag, to the page... so I'll have to go from memory.  Normally you can paste things and back up what you are saying, but today that's not happenin ...\n",
      "Coop Query: Comprehensive biography of Freddy Krueger: origins, characteristics, role in A Nightmare on Elm Street franchise, and cultural significance.\n",
      "--------------------------------------------------------------------------------\n",
      "Q: who was the star on this movie?\n",
      "Pred: Based on the context, the star of the film is the male main protagonist, as described in the references to a \"film with a male main protagonist\" and a character who fights alongside that star. For a more accurate response, could you provide the movie title? ...\n",
      "Gold: Robert Englund IS Freddy Kruger, the bad guy for these films. Note to you and to Adam, the Pragmatic one, the link here is broken and I can't paste relevant things, as has always been Nightmare's case, I'm perfectly good with answering your questions and will quickly do it, but have to open a tab in ...\n",
      "Coop Query: What is the title of the movie in question?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Run Multi-Step module on first questions and save outputs ===\n",
    "import os, json, time\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "OUT_DIR = os.path.join(HW3_ROOT, \"outputs\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "PRED_JSONL = os.path.join(OUT_DIR, \"val_firstq_multistep_predictions.jsonl\")\n",
    "\n",
    "def run_first_questions_multistep(\n",
    "    examples: List[FirstTurnExample],\n",
    "    module: MultiStepCoopQAModule,\n",
    "    top_k: int = TOP_K_RETRIEVE,\n",
    "    limit: Optional[int] = None,\n",
    "    save_path: Optional[str] = None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    N = len(examples) if limit is None else min(limit, len(examples))\n",
    "    t0 = time.time()\n",
    "\n",
    "    for ex in tqdm(examples[:N], total=N, desc=\"MultiStep on first questions\"):\n",
    "        try:\n",
    "            initial_ctx = retrieve_context(ex.topic, ex.question, top_k=top_k)\n",
    "\n",
    "            out = module(\n",
    "                topic=ex.topic,\n",
    "                question=ex.question,\n",
    "                history=None,             \n",
    "                initial_context=initial_ctx,\n",
    "                top_k=top_k\n",
    "            )\n",
    "\n",
    "            rec: Dict[str, Any] = {\n",
    "                \"conversation_id\": ex.conversation_id,\n",
    "                \"topic\": ex.topic,\n",
    "                \"question\": ex.question,\n",
    "                \"pred_answer\": out.get(\"answer\", \"\"),\n",
    "                \"gold_answer\": ex.gold_answer,\n",
    "                \"literal_spans\": ex.literal_spans,\n",
    "                \"pragmatic_spans\": ex.pragmatic_spans,\n",
    "                \"history_summary\": out.get(\"history_summary\", \"\"),\n",
    "                \"pragmatic_need\": out.get(\"pragmatic_need\", \"\"),\n",
    "                \"coop_query\": out.get(\"coop_query\", \"\"),\n",
    "                \"context_1\": out.get(\"context_1\", []),\n",
    "                \"context_all\": out.get(\"context_all\", []),\n",
    "                \"reasoning\": out.get(\"reasoning\", \"\"),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            rec = {\n",
    "                \"conversation_id\": ex.conversation_id,\n",
    "                \"topic\": ex.topic,\n",
    "                \"question\": ex.question,\n",
    "                \"pred_answer\": \"\",\n",
    "                \"gold_answer\": ex.gold_answer,\n",
    "                \"literal_spans\": ex.literal_spans,\n",
    "                \"pragmatic_spans\": ex.pragmatic_spans,\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "        results.append(rec)\n",
    "\n",
    "        if save_path:\n",
    "            with open(save_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[INFO] Done {N} examples in {dt:.1f}s ({dt/max(N,1):.2f}s/ex)\")\n",
    "    print(f\"[INFO] Saved to: {save_path}\" if save_path else \"[INFO] Not saved (save_path=None)\")\n",
    "    return results\n",
    "\n",
    "if os.path.exists(PRED_JSONL):\n",
    "    os.remove(PRED_JSONL)\n",
    "\n",
    "val_firstq_preds = run_first_questions_multistep(\n",
    "    val_first_q_examples,\n",
    "    multi_step,\n",
    "    top_k=TOP_K_RETRIEVE,\n",
    "    limit=None,                   \n",
    "    save_path=PRED_JSONL\n",
    ")\n",
    "\n",
    "print(f\"Total predictions: {len(val_firstq_preds)}\")\n",
    "for rec in val_firstq_preds[:2]:\n",
    "    print(\"-\"*80)\n",
    "    print(\"Q:\", rec[\"question\"])\n",
    "    print(\"Pred:\", (rec[\"pred_answer\"] or \"\")[:300], \"...\")\n",
    "    print(\"Gold:\", (rec[\"gold_answer\"] or \"\")[:300], \"...\")\n",
    "    print(\"Coop Query:\", rec.get(\"coop_query\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c087f96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.234178</td>\n",
       "      <td>0.361455</td>\n",
       "      <td>0.260406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.211046</td>\n",
       "      <td>0.320411</td>\n",
       "      <td>0.217244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision      recall          f1\n",
       "count  179.000000  179.000000  179.000000\n",
       "mean     0.234178    0.361455    0.260406\n",
       "std      0.211046    0.320411    0.217244\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%      0.000000    0.000000    0.000000\n",
       "50%      0.200000    0.330000    0.250000\n",
       "75%      0.333000    0.500000    0.400000\n",
       "max      0.800000    1.000000    0.857143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dspy.evaluate import SemanticF1\n",
    "import pandas as pd\n",
    "\n",
    "metric = SemanticF1()\n",
    "\n",
    "def prf1(q, gold, pred):\n",
    "    s = metric.module(\n",
    "        question=q or \"\",\n",
    "        ground_truth=str(gold or \"\"),\n",
    "        system_response=str(pred or \"\")\n",
    "    )\n",
    "    p, r = float(s.precision), float(s.recall)\n",
    "    f1 = 2 * p * r / (p + r + 1e-9)\n",
    "    return p, r, f1\n",
    "\n",
    "p_vals, r_vals, f1_vals = zip(*[\n",
    "    prf1(r[\"question\"], r[\"gold_answer\"], r[\"pred_answer\"])\n",
    "    for r in val_firstq_preds\n",
    "])\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    \"topic\":    [r.get(\"topic\", \"\")    for r in val_firstq_preds],\n",
    "    \"question\": [r.get(\"question\", \"\") for r in val_firstq_preds],\n",
    "    \"gold\":     [r.get(\"gold_answer\")  for r in val_firstq_preds],\n",
    "    \"pred\":     [r.get(\"pred_answer\")  for r in val_firstq_preds],\n",
    "    \"precision\": p_vals,\n",
    "    \"recall\":    r_vals,\n",
    "    \"f1\":        f1_vals,\n",
    "})\n",
    "\n",
    "display(scores_df[[\"precision\", \"recall\", \"f1\"]].astype(float).describe())\n",
    "scores_df.to_csv(\"part4_4_1_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f999149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def load_all_turns(val_jsonl_path: Path) -> List[Dict[str, Any]]:\n",
    "    all_data = []\n",
    "    with open(val_jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            convo = json.loads(line)\n",
    "            topic = convo.get(\"topic\", \"\")\n",
    "            qas = convo.get(\"qas\", [])\n",
    "\n",
    "            all_data.append({\n",
    "                \"topic\": topic,\n",
    "                \"qas\": qas\n",
    "            })\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_jsonl_path = Path(\"/PragmatiCQA/data/val.jsonl\") \n",
    "val_conversations = load_all_turns(val_jsonl_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
